---
title: "AnalisiDadesCliniques"
format: html
editor: visual
---

```{r}
colorTFG <- rgb(91, 200, 145, maxColorValue = 250)
```

## Paquets necessaris

A continuació, carregarem els paquets necessaris per a dur a terme l'estudi de les dades clíniques

```{r}
library(tidyverse)
library(glmnet)
library(dplyr)
library(randomForest)
library(splines)
library(gam)
```

## Lectura de la base de dades

Primer de tot llegim els csv generats durant el processament de les dades clíniques.

```{r}
clinical <- read.csv("Clinical Data csv/clinical_data_processed.csv")
#str(clinical)

clinical_train <- read.csv("Clinical Data csv/clinical_data_processed_train.csv")
#str(clinical_train)

clinical_test <- read.csv("Clinical Data csv/clinical_data_processed_test.csv")
#str(clinical_test)
```

## Funcions útils

Funció que calcula el MSE:

```{r}
mse <- function(real, prediccio) {
  return(mean((real - prediccio)^2))
}
```

Funció que calcula el $R^2$:

```{r}
r_squared <- function(actual, predicted) {
  
  ss_residual <- sum((actual - predicted)^2)
  ss_total <- sum((actual - mean(actual))^2)
  
  return(1 - (ss_residual / ss_total))
}
```

## Model baseline

Realitzarem un model de referència que no utilitza cap variable amb l'objectiu de poder comparar-lo en el futur amb els nous models entrenats

```{r}
clinical_train_resposta <- clinical_train$OS
clinical_test_resposta <- clinical_test$OS 
clinical_test_id <- clinical_test$TCIA_ID
```

Calculam la mitjana de l'*OS* dels pacients inclosos en el connjunt d'entrenament.

```{r}
prediccio = mean(clinical_train_resposta)
prediccio
```

Per tant, la predicció és $124.9$ setmanes.

```{r}

r2_base <- r_squared(clinical_test_resposta, prediccio)
r2_base

mse_base <- mse(clinical_test_resposta, prediccio)
mse_base
```

## Regressió lineal

Eliminam la variable que és la clau primària per a facilitar la implementació dels models.

```{r}

clinical_test <- clinical_test %>% select(-TCIA_ID)
clinical_train <- clinical_train %>% select(-TCIA_ID)
```

A continuació, construïm el model lineal amb les dades d'entrenament.

```{r}
rl <- lm(OS ~ . , data = clinical_train)

summary(rl)
```

Ara, feim la predicció de la variable $OS$ utilitzant el model anterior damunt les dades test.

```{r}
predict <-  predict(rl, newdata = clinical_test)

tabla_predict <- data.frame(clinical_test_id, predict, clinical_test_resposta)
tabla_predict

plot(x = clinical_test_resposta, y =predict, xlab = "Valors reals", ylab = "Predicció", main = 
       "Comparació de la predicció amb els valors reals", ylim = c(0, 400), xlim = c(0,400), col = colorTFG, pch =16,
     col.main = "black")
abline(a = 0, b = 1, col = "red", lty = 2)

```

Calculam el MSE I $R^2$:

```{r}

r2_lineal <- r_squared(clinical_test_resposta, predict)
r2_lineal

mse_lineal <- mse(clinical_test_resposta, predict)
mse_lineal
```

Finalment, observem la distribució dels residus.

```{r}
#plot(rl)

```

```{r}
residuals <- resid(rl)

qq_plot <- ggplot(data.frame(residuals), aes(sample = residuals)) +
  stat_qq(color = colorTFG, size = 2) + 
  stat_qq_line(color = "red", linetype = "dashed", size = 1) + 
  labs(title = "Q-Q Plot dels Residus", x = "Quantils Teòrics", y = "Quantils dels Residus") +
  theme_minimal() + 
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12) 
  )

print(qq_plot)
```

## Regressió LASSO

A n'aquesta secció implementarem el model LASSO a les dades clíniques

Cream una matriu de les variables predictors i un vector amb la resposta.

```{r}
matriz_pred <- clinical %>% 
  select(-TCIA_ID, -OS) %>% 
  as.matrix()

resposta <- clinical$OS
```

A continuació, entrenam el model a les dades d'entrenament

```{r}
# Recordam que per a realitzar el conjunt train i test vam utilitzar la 
# set.seed 2024
set.seed(2024)
train = sample(1:nrow(clinical), 70)

modelo_lasso <- glmnet(matriz_pred[train, ], resposta[train], alpha = 1)

plot(modelo_lasso, xvar = "lambda", xlab = expression(log(lambda)), ylab = "Coeficients")
plot(modelo_lasso, xvar = "dev")
```

Utilitzam cross-validation per a triar el valor òptim de lambda

```{r}
cv.out <- cv.glmnet(matriz_pred[train, ], resposta[train], alpha = 1)
plot(cv.out, main = expression("Error quadràtic mitjà - Paràmetre" ~ lambda))
bestlam <- cv.out$lambda.min
lasso.pred <- predict(modelo_lasso, s=bestlam, newx= matriz_pred[-train, ])
#mean((lasso.pred-resposta[-train])^2)
```

Finalment, aconseguim els valors dels coeficients

```{r}
lasso.coef <- predict(modelo_lasso, type = "coefficients", s = bestlam)
lasso.coef
```

Obtenim el mateix model de referència inicial.

Si ara per exemple triam un valor de $\lambda$ que conservi almenys algunes variables, per exemple $\lambda = 15$ :

```{r}
lasso.pred <- predict(modelo_lasso, s=15, newx= matriz_pred[-train, ])
lasso.coef <- predict(modelo_lasso, type = "coefficients", s = 15)
lasso.coef

```

Calculam el MSE I el $R^2$:

```{r}
r2_lasso <- r_squared(clinical_test_resposta, lasso.pred)
r2_lasso

mse_lasso <- mse(clinical_test_resposta, lasso.pred)
mse_lasso
```

## Random forest

```{r}
set.seed(2024)
train = sample(1:nrow(clinical), 70)
rf.clinical_data <- randomForest(OS ~. - TCIA_ID, data = clinical, subset = train, mtry = 1)
rf.clinical_data
yhat <- predict(rf.clinical_data, newdata = clinical[-train, ])
clinical.test <- clinical[-train,]$OS
mean((yhat - clinical.test)^2 )
#yhat

plot(rf.clinical_data)
```

```{r}
oob.err = double(13)
test.err = double(13)

for (mtry in 1:15){
  fit <- randomForest(OS ~. - TCIA_ID, data = clinical, subset = train, mtry = mtry)
  oob.err[mtry] = fit$mse[600]
  pred =  predict(fit, newdata = clinical[-train, ])
  test.err[mtry] = with(clinical[-train,], mean((OS-pred)^2))
  print(mtry)
}

test.err

```

```{r}
# Calculam R^2 de les dades test

r2 = 1 - (sum((clinical_test_resposta - yhat)^2)) / (sum((clinical_test_resposta - 
                                                           mean(clinical_test_resposta))^2))
r2

mse = mean((clinical_test_resposta - yhat)^2)

mse
```

```{r}
importance(rf.clinical_data)
```

```{r}
importance_df <- as.data.frame(importance(rf.clinical_data))

# Afegir noms de columnes per claredat
colnames(importance_df) <- c("IncNodePurity")

# Ordenar les variables per importància decreixent
importance_df$Variable <- rownames(importance_df)
importance_df <- importance_df[order(importance_df$IncNodePurity, decreasing = TRUE), ]

# Gràfica de barres de la importància de les variables
ggplot(importance_df, aes(x = reorder(Variable, IncNodePurity), y = IncNodePurity), col = colorTFG) +
  geom_bar(stat = "identity", fill = colorTFG) +
  coord_flip() +
  xlab("") +
  ylab("Increment de la Puresa del Node (IncNodePurity)") +
  ggtitle("Importància de les Variables en el Model de Random Forest") + 
  theme_minimal()
```

## GAM

```{r}
gam2 <- gam(OS ~ns(age,5) + ns(AFP,5)+ Diabetes +Alcohol+ age + Sex + Smoking + T_involvment + Evidence_of_cirh + hepatitis_HCV + hepatitis_HBV + Portal_Vein_Thrombosis + Vascular_Invasion + tumor_nodul + Personal_history_cancer + fhx_can, data = clinical_train)
plot(gam2, se = TRUE, col="blue")
```

```{r}
summary(gam2)
```

```{r}
pred = predict(gam2, newdata = clinical_test)
pred
```

```{r}
r2 = 1 - (sum((clinical_test_resposta - pred)^2)) / (sum((clinical_test_resposta - 
                                                           mean(clinical_test_resposta))^2))
r2

mse = mean((clinical_test_resposta - pred)^2)

mse

```
