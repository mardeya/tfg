---
title: "AnalisiDadesCliniques"
format: html
editor: visual
---

```{r}
colorTFG <- rgb(91, 200, 145, maxColorValue = 250)
```

## Paquets necessaris

A continuació, carregarem els paquets necessaris per a dur a terme l'estudi de les dades clíniques

```{r}
library(tidyverse)
library(glmnet)
library(dplyr)
library(randomForest)
library(splines)
library(gam)
library(caret)
library(mgcv)
```

## Lectura de la base de dades

Primer de tot llegim els csv generats durant el processament de les dades clíniques.

```{r}
clinical <- read.csv("Clinical Data csv/clinical_data_processed.csv")
#str(clinical)

clinical_train <- read.csv("Clinical Data csv/clinical_data_processed_train.csv")
#str(clinical_train)

clinical_test <- read.csv("Clinical Data csv/clinical_data_processed_test.csv")
#str(clinical_test)
```

## Funcions útils

Funció que calcula el MSE:

```{r}
mse <- function(real, prediccio) {
  return(mean((real - prediccio)^2))
}
```

Funció que calcula el $R^2$:

```{r}
r_squared <- function(actual, predicted) {
  
  ss_residual <- sum((actual - predicted)^2)
  ss_total <- sum((actual - mean(actual))^2)
  
  return(1 - (ss_residual / ss_total))
}
```

Funció que calcula el \$R\^2\$ ajustat:

```{r}
adjusted_r2 <- function(r2, n, p) {
  adj_r2 <- 1 - ((1 - r2) * (n - 1) / (n - p - 1))
  return(adj_r2)
}
# n nombre d'observacions, p nombre de variables utilitzades
```

Funció per a dur a terme la validació creuada

```{r}
train_control <- trainControl(method = "cv", number = 5)
```

## Model baseline

Realitzarem un model de referència que no utilitza cap variable amb l'objectiu de poder comparar-lo en el futur amb els nous models entrenats

```{r}
clinical_train_resposta <- clinical_train$OS
clinical_test_resposta <- clinical_test$OS 
clinical_test_id <- clinical_test$TCIA_ID
```

Calculam la mitjana de l'*OS* dels pacients inclosos en el connjunt d'entrenament.

```{r}
prediccio = mean(clinical_train_resposta)
prediccio
```

Per tant, la predicció és $124.9$ setmanes.

```{r}

r2_base <- r_squared(clinical_test_resposta, prediccio)
r2_base

mse_base <- mse(clinical_test_resposta, prediccio)
mse_base
```

## Regressió lineal

Eliminam la variable que és la clau primària per a facilitar la implementació dels models.

```{r}

clinical_test <- clinical_test %>% select(-TCIA_ID)
clinical_train <- clinical_train %>% select(-TCIA_ID)
```

A continuació, construïm el model lineal amb les dades d'entrenament.

```{r}
rl <- lm(OS ~ . , data = clinical_train)

summary(rl)
```

Validació creuada

```{r}
model <- train(
  OS ~ .,
  data = clinical_train,
  trControl = train_control
)
print(model)
```

Ara, feim la predicció de la variable $OS$ utilitzant el model anterior damunt les dades test.

```{r}
predict <-  predict(rl, newdata = clinical_test)

tabla_predict <- data.frame(clinical_test_id, predict, clinical_test_resposta)
tabla_predict

plot(x = clinical_test_resposta, y =predict, xlab = "Valors reals", ylab = "Predicció", main = 
       "Comparació de la predicció amb els valors reals", ylim = c(0, 400), xlim = c(0,400), col = colorTFG, pch =16,
     col.main = "black")
abline(a = 0, b = 1, col = "red", lty = 2)

```

Calculam el MSE I $R^2$:

```{r}

r2_lineal <- r_squared(clinical_test_resposta, predict)
r2_lineal

mse_lineal <- mse(clinical_test_resposta, predict)
mse_lineal
```

Finalment, observem la distribució dels residus.

```{r}
#plot(rl)

```

```{r}
residuals <- resid(rl)

qq_plot <- ggplot(data.frame(residuals), aes(sample = residuals)) +
  stat_qq(color = colorTFG, size = 2) + 
  stat_qq_line(color = "red", linetype = "dashed", size = 1) + 
  labs(title = "Q-Q Plot dels Residus", x = "Quantils Teòrics", y = "Quantils dels Residus") +
  theme_minimal() + 
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12) 
  )

print(qq_plot)
```

## Regressió LASSO

A n'aquesta secció implementarem el model LASSO a les dades clíniques

Cream una matriu de les variables predictors i un vector amb la resposta.

```{r}
matriz_pred <- clinical %>% 
  select(-TCIA_ID, -OS) %>% 
  as.matrix()

resposta <- clinical$OS
```

A continuació, entrenam el model a les dades d'entrenament

```{r}
# Recordam que per a realitzar el conjunt train i test vam utilitzar la 
# set.seed 2024
set.seed(2024)
train = sample(1:nrow(clinical), 70)

modelo_lasso <- glmnet(matriz_pred[train, ], resposta[train], alpha = 1)

plot(modelo_lasso, xvar = "lambda", xlab = expression(log(lambda)), ylab = "Coeficients")
plot(modelo_lasso, xvar = "dev")
```

Utilitzam cross-validation per a triar el valor òptim de lambda

```{r}
cv.out <- cv.glmnet(matriz_pred[train, ], resposta[train], alpha = 1)
plot(cv.out, main = expression("Error quadràtic mitjà - Paràmetre" ~ lambda))
bestlam <- cv.out$lambda.min
lasso.pred <- predict(modelo_lasso, s=bestlam, newx= matriz_pred[-train, ])
#mean((lasso.pred-resposta[-train])^2)
```

Finalment, aconseguim els valors dels coeficients

```{r}
lasso.coef <- predict(modelo_lasso, type = "coefficients", s = bestlam)
lasso.coef
```

Obtenim el mateix model de referència inicial.

Si ara per exemple triam un valor de $\lambda$ que conservi almenys algunes variables, per exemple $\lambda = 5$ :

```{r}
lasso.pred <- predict(modelo_lasso, s=5, newx= matriz_pred[-train, ])
lasso.coef <- predict(modelo_lasso, type = "coefficients", s = 5)
lasso.coef

```

Calculam el MSE I el $R^2$:

```{r}
r2_lasso <- r_squared(clinical_test_resposta, lasso.pred)
r2_lasso

mse_lasso <- mse(clinical_test_resposta, lasso.pred)
mse_lasso

adjusted_r2_lasso <- adjusted_r2(r2_lasso, 35, 11)
adjusted_r2_lasso
```

Validació creuada del model

```{r}
lasso_model <- train(matriz_pred[train,], resposta[train],
                     method = "glmnet",
                     trControl = train_control,
                     tuneGrid = expand.grid(alpha = 1, lambda = 5)
)
print(lasso_model)
```

Gràfic comparatiu dels resultats

```{r}

tabla_predict <- data.frame(clinical_test_id, lasso.pred, clinical_test_resposta)
tabla_predict

plot(x = clinical_test_resposta, y =lasso.pred, xlab = "Valors reals", ylab = "Predicció", main = 
       "Comparació de la predicció amb els valors reals", ylim = c(0, 400), xlim = c(0,400), col = colorTFG, pch =16,
     col.main = "black")
abline(a = 0, b = 1, col = "red", lty = 2)

```

## Random forest

En aquest apartat, entrenarem el model de Random Forest a les nostres dades clíniques.
```{r}
set.seed(2024)
train = sample(1:nrow(clinical), 70)
rf.clinical_data <- randomForest(OS ~. - TCIA_ID, data = clinical, subset = train, mtry = 1, trees = 50)
rf.clinical_data
yhat <- predict(rf.clinical_data, newdata = clinical[-train, ], trees = 50)
clinical.test <- clinical[-train,]$OS
mean((yhat - clinical.test)^2 )
#yhat

plot(rf.clinical_data)
```
Vegem quina mètrica seleccionar per a entrenar el nostre model.
```{r}
oob.err = double(13)
test.err = double(13)

for (mtry in 1:15){
  fit <- randomForest(OS ~. - TCIA_ID, data = clinical, subset = train, mtry = mtry)
  oob.err[mtry] = fit$mse[600]
  pred =  predict(fit, newdata = clinical[-train, ])
  test.err[mtry] = with(clinical[-train,], mean((OS-pred)^2))
}

```


```{r}
plot(1:15, test.err, type = "b", pch = 19, col = colorTFG, 
     xlab = "Mètrica", ylab = "MSE", main = "MSE vs. mètrica",
     ylim = c(min(test.err) - 0.5, max(test.err) + 0.5))
lines(1:15, test.err, col = colorTFG, type = "b", pch = 19)
grid()  # Afegir graella de fons
legend("topright", legend = "MSE", col = colorTFG, pch = 19)

# Mostrar el punt amb l'error mínim
min_test_err <- min(test.err)
min_mtry <- which(test.err == min_test_err)
points(min_mtry, min_test_err, col = "red", pch = 19)
text(min_mtry + 0.5, min_test_err, paste("Mínim MSE"), pos = 4, col = "red")
```
Validació creuada

```{r}
rf_model <- train(matriz_pred[train,], resposta[train],
                  method = "rf",
                  trControl = train_control,
                  metric = "Rsquared")
print(rf_model)
```


Calculam les mètriques de l'ajustament

```{r}
# Calculam R^2 de les dades test

r2_rf <- r_squared(clinical_test_resposta, yhat)
r2_rf

mse_rf <- mse(clinical_test_resposta,yhat)

mse_rf
```


Finalment, vegem quines han estat les variables més importants a l'hora de crear 
el noste model.
```{r}
importance(rf.clinical_data)
```

```{r}
importance_df <- as.data.frame(importance(rf.clinical_data))

# Afegir noms de columnes per claredat
colnames(importance_df) <- c("IncNodePurity")

# Ordenar les variables per importància decreixent
importance_df$Variable <- rownames(importance_df)
importance_df <- importance_df[order(importance_df$IncNodePurity, decreasing = TRUE), ]

# Gràfica de barres de la importància de les variables
ggplot(importance_df, aes(x = reorder(Variable, IncNodePurity), y = IncNodePurity), col = colorTFG) +
  geom_bar(stat = "identity", fill = colorTFG) +
  coord_flip() +
  xlab("") +
  ylab("Increment de la Puresa del Node (IncNodePurity)") +
  ggtitle("Importància de les Variables en el Model de Random Forest") + 
  theme_minimal()
```



## GAM

En aquest apartat entrenarem el model GAM per a intentar trobar un relació no 
lineal entre els prdictors i la variable resposta.

```{r}
gam2 <- gam(OS ~ s(age) + s(AFP)+ Diabetes +Alcohol + Sex + Smoking + T_involvment + Evidence_of_cirh + hepatitis_HCV + hepatitis_HBV + Portal_Vein_Thrombosis + Vascular_Invasion + tumor_nodul + Personal_history_cancer + fhx_can, data = clinical_train)
#summary(gam2)
plot(gam2, se = TRUE, col=colorTFG)
```

Durem a terme la validació creuada
```{r}
gam_model <- train(
  OS ~ s(age) + s(AFP)+ Diabetes +Alcohol + Sex + Smoking + T_involvment + Evidence_of_cirh + hepatitis_HCV + hepatitis_HBV + Portal_Vein_Thrombosis + Vascular_Invasion + tumor_nodul + Personal_history_cancer + fhx_can,
  data = clinical_train,
  method = "gam",
  trControl = train_control)

```


```{r}
summary(gam2)
```

```{r}
pred = predict(gam2, newdata = clinical_test)
pred
```

```{r}
r2_gam <- r_squared(clinical_test_resposta, pred)
r2_gam

mse_gam <- mse(clinical_test_resposta, pred)
mse_gam

```
