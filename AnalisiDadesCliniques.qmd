---
title: "AnalisiDadesCliniques"
format: html
editor: visual
---

## Regressió lineal

```{r}
clinical <- read.csv("clinical_data_processed.csv")
str(clinical)
```

```{r}
regressio_lineal = lm(OS ~. - TCIA_ID, data = clinical)
summary(regressio_lineal)

```

```{r}
plot(regressio_lineal)
```

Entre d'altres, el Multiple R-Squared és baix. Per tant, el model no és bo.

## Regressió LASSO

Cream una matriu de les variables predictors i un vector amb la resposta

```{r}
matriz_pred <- clinical %>% 
  select(-TCIA_ID, -OS) %>% 
  as.matrix()

resposta <- clinical$OS
```

```{r}
set.seed(2024)
train = sample(1:nrow(clinical), 70)
grid <- 10^seq(10,-2, length=100)
modelo_lasso <- glmnet(matriz_pred[train, ], resposta[train], alpha = 1, lambda = grid)
plot(modelo_lasso)
```

```{r}
cv.out <- cv.glmnet(matriz_pred[train, ], resposta[train], alpha = 1)
#plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(modelo_lasso, s=bestlam, newx= matriz_pred[-train, ])
mean((lasso.pred-resposta[-train])^2)
```

Finalment, aconseguim els valors dels coeficients

```{r}
out <- glmnet(matriz_pred, resposta, alpha = 1, lambda = grid)
lasso.coef <- predict(modelo_lasso, type = "coefficients", s = bestlam)
lasso.coef
```

## Random forest

```{r}
library(randomForest)
```

```{r}
set.seed(2024)
train = sample(1:nrow(clinical), 70)
rf.clinical_data <- randomForest(OS ~. - TCIA_ID, data = clinical, subset = train, mtry = 10, 
                                 importance = TRUE)
yhat <- predict(rf.clinical_data, newdata = clinical[-train, ])
clinical.test <- clinical[-train,]$OS
mean((yhat - clinical.test)^2 )
```

```{r}
importance(rf.clinical_data)
```
