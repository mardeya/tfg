---
title: "analisi dades radiomiques"
format: html
editor: visual
---

## Paquets necessaris

Primer de tot carregam tots el paquets necessaris i carregam el color propi de la memòria del TFG.

```{r}
library(glmnet)
library(dplyr)
library(readxl)
library(ggplot2)
library(factoextra)
library(pls)
library(gplots)
library(caret)
library(randomForest)

colorTFG <- rgb(91, 200, 145, maxColorValue = 250)
```

## Lectura de la base de dades

A continuació, llegim els csv pertinents:

```{r}
radiomica <- read.csv("Radiomica Data csv/radiomica_data_processed.csv")
#str(clinical)

radiomica_train <- read.csv("Radiomica Data csv/radiomica_data_processed_train.csv")
#str(clinical_train)

radiomica_test <- read.csv("Radiomica Data csv/radiomica_data_processed_test.csv")
#str(clinical_test)
```

## Funcions útils

Funció que calcula el MSE:

```{r}
mse <- function(real, prediccio) {
  return(mean((real - prediccio)^2))
}
```

Funció que calcula el $R^2$:

```{r}
r_squared <- function(actual, predicted) {
  
  ss_residual <- sum((actual - predicted)^2)
  ss_total <- sum((actual - mean(actual))^2)
  
  return(1 - (ss_residual / ss_total))
}
```

Per a utilitzar validació creuada:

```{r}
train_control <- trainControl(method = "cv", number = 5)
```

## Model baseline

Realitzarem un model de referència que no utilitza cap variable amb l'objectiu de poder comparar-lo en el futur amb els nous models entrenats

```{r}
radiomica_train_resposta <- radiomica_train$OS
radiomica_test_resposta <- radiomica_test$OS 
radiomica_test_id <- radiomica_test$Patient
```

Calculam la mitjana de l'*OS* dels pacients inclosos en el connjunt d'entrenament.

```{r}
prediccio = mean(radiomica_train_resposta)
prediccio
```

Per tant, la predicció és $125.7776$ setmanes.

```{r}

r2_base <- r_squared(radiomica_test_resposta, prediccio)
r2_base

mse_base <- mse(radiomica_test_resposta, prediccio)
mse_base
```

## Regressió lineal

Realitzarem tres regressions lineals, cada una amb un mètode diferent per a afrontar el problema de grans dimensions

### Selecció de variables

Eliminam la variable que és la clau primària:

```{r}

radiomica_test <- radiomica_test %>% select(-Patient)
radiomica_train <- radiomica_train %>% select(-Patient)
```

Model base sense cap variable:

```{r}
rl_step <- lm(OS ~ 1 , data = radiomica_train)

summary(rl_step)
```

```{r}
rl_step <- step(rl_step, direction = "both", trace = TRUE)
summary(rl_step)
```

### PCA

A n'aquest apartat realitzarem un anàlisi de components principals i la posterior regressió.

Ens agafam les cinc primeres dimensions ja que agrupen el 80% de la variança.

```{r}
pcr.regression <- pcr(OS ~., data =  radiomica_train, scale = TRUE, validation = "CV") 
summary(pcr.regression)
```

```{r}
validationplot(pcr.regression, val.type = "MSEP")
```

Elegirem aleshores 6 components

```{r}
pcr.fit <- pcr(OS ~., data = radiomica_train , scale = TRUE, ncomp = 15)
summary(pcr.fit)
```

```{r}
pcr.pred <- predict(pcr.fit, radiomica_test, ncomp = 10)
pcr.pred[,,]
```

```{r}
mse(pcr.pred, radiomica_test$OS)
r_squared(pcr.pred, radiomica_test$OS)
```

```{r}
explained_variance <- explvar(pcr.regression)[0:10]
```

```{r}
components_df <- data.frame(
  Component = seq_along(explained_variance),
  VarianceExplained = explained_variance
)

# Gráfico de codo
ggplot(components_df, aes(x = Component)) +
  geom_bar(aes(y = VarianceExplained), stat = "identity", fill = colorTFG) +
  geom_line(aes(y = VarianceExplained, group = 1), color = "red") +
  geom_point(aes(y = VarianceExplained), color = "red") +
  geom_text(aes(y = VarianceExplained, label = sprintf("%.1f%%", VarianceExplained)), 
            vjust = -0.5, size = 3) +
  scale_x_continuous(breaks = seq_along(explained_variance)) +
  labs(title = "Scree plot",
       x = "Componentes Principales",
       y = "Varianza Explicada (%)") +
  theme_minimal()
```

### Anàlisi de la col·linealitat

A continuació, realitzarem un anàlisi de col·linealitat per a eliminar les variables altament correlacionades.

```{r}
OS <- radiomica_train$OS
radiomica_data_quant <- radiomica_train %>% 
  select(-OS)

corr_matrix <- cor(radiomica_data_quant)

high_corr <- which(abs(corr_matrix) > 0.75 & upper.tri(corr_matrix), arr.ind = TRUE)

var_counts <- table(c(rownames(corr_matrix)[high_corr[,1]], colnames(corr_matrix)[high_corr[,2]]))

for (i in 1:nrow(high_corr)) {
  var1 <- rownames(corr_matrix)[high_corr[i, 1]]
  var2 <- colnames(corr_matrix)[high_corr[i, 2]]
  if (var1 %in% colnames(radiomica_data_quant) && var2 %in% colnames(radiomica_data_quant)) {
    if (var_counts[var1] <= var_counts[var2]) {
      radiomica_data_quant <- radiomica_data_quant[, !colnames(radiomica_data_quant) %in% var1]
    } else {
      radiomica_data_quant <- radiomica_data_quant[, !colnames(radiomica_data_quant) %in% var2]
    }
  }
}

```

Ara vegem un mapa de calor de les variables finals

```{r}
colorTFGi <- rgb(91, 200, 145, maxColorValue = 300)
my_colors <- colorRampPalette(c("white", colorTFGi))(n = 299)
#cor(radiomica_data_quant)
heatmap(cor(radiomica_data_quant), col = my_colors,cexCol = 0.8,
           margins = c(17, 4))
```

```{r}
radiomica_colin_train <- cbind(radiomica_data_quant,OS)
radiomica_colin_test <- radiomica_test[, colnames(radiomica_colin_train)]
```

A continuació, construïm el model lineal amb les dades d'entrenament.

```{r}
rl <- lm(OS ~ . , data = radiomica_colin_train)

summary(rl)
```

```{r}
model <- train(
  OS ~ .,
  data = radiomica_colin_train,
  trControl = train_control
)
print(model)
```

Predicció sobre dades test

```{r}
predict <-  predict(rl, newdata = radiomica_colin_test)

#tabla_predict <- data.frame(radiomica_test_id, predict, radiomica_test_resposta)

plot(x = radiomica_test_resposta, y =predict, xlab = "Valors reals", ylab = "Predicció", main = 
       "Comparació de la predicció amb els valors reals", ylim = c(0, 400), xlim = c(0,400), col = colorTFG, pch 
       =16,
     col.main = "black")
abline(a = 0, b = 1, col = "red", lty = 2)

```

## 

Calculam el MSE I $R^2$:

```{r}

r2_lineal <- r_squared(radiomica_test_resposta, predict)
r2_lineal

mse_lineal <- mse(radiomica_test_resposta, predict)
mse_lineal
```

Finalment, observem la distribució dels residus.

```{r}
#plot(rl)

```

```{r}
residuals <- resid(rl)

qq_plot <- ggplot(data.frame(residuals), aes(sample = residuals)) +
  stat_qq(color = colorTFG, size = 2) + 
  stat_qq_line(color = "red", linetype = "dashed", size = 1) + 
  labs(title = "Q-Q Plot dels Residus", x = "Quantils Teòrics", y = "Quantils dels Residus") +
  theme_minimal() + 
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12) 
  )

print(qq_plot)
```

## Regressió LASSO

Cream una matriu de les variables predictors i un vector amb la resposta

```{r}
matriz_pred <- radiomica[, colnames(radiomica_colin_train)] %>% 
  select(-OS) %>% 
  as.matrix()

resposta <-radiomica$OS
```

```{r}
set.seed(2024)
train = sample(1:nrow(radiomica), 70)
modelo_lasso <- glmnet(matriz_pred[train, ], resposta[train], alpha = 1)
plot(modelo_lasso, xvar = "lambda", xlab = expression(log(lambda)), ylab = "Coeficients")
plot(modelo_lasso, xvar = "dev")
```

```{r}
cv.out <- cv.glmnet(matriz_pred[train, ], resposta[train], alpha = 1)
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(modelo_lasso, s=bestlam, newx= matriz_pred[-train, ])
#mean((lasso.pred-resposta[-train])^2)
```

Finalment, aconseguim els valors dels coeficients

```{r}
lasso.coef <- predict(modelo_lasso, type = "coefficients", s = 10)
lasso.coef
```

Calculam el MSE I el $R^2$:

```{r}
r2_lasso <- r_squared(radiomica_test_resposta, lasso.pred)
r2_lasso

mse_lasso <- mse(radiomica_test_resposta, lasso.pred)
mse_lasso

#adjusted_r2_lasso <- adjusted_r2(r2_lasso, 35, 11)
#adjusted_r2_lasso
```

Validació creuada del model

```{r}
lasso_model <- train(matriz_pred[train,], resposta[train],
                     method = "glmnet",
                     trControl = train_control,
                     tuneGrid = expand.grid(alpha = 1, lambda = 5)
)
print(lasso_model)
```

## Random forest

En aquest apartat, entrenarem el Random Forest

```{r}
set.seed(2024)
train = sample(1:nrow(radiomica), 70)

radiomica <- radiomica[,colnames(radiomica_colin_train)]
rf.radiomica_data <- randomForest(OS ~. , data = radiomica, subset = train, mtry = 1)
rf.radiomica_data
yhat <- predict(rf.radiomica_data, newdata = radiomica[-train, ])
clinical.test <- radiomica[-train,]$OS
mean((yhat - radiomica_test_resposta)^2 )
#yhat
```

```{r}
oob.err = double(13)
test.err = double(13)

for (mtry in 1:15){
  fit <- randomForest(OS ~., data = radiomica, subset = train, mtry = mtry)
  oob.err[mtry] = fit$mse[600]
  pred =  predict(fit, newdata = radiomica[-train, ])
  test.err[mtry] = with(radiomica[-train,], mean((OS-pred)^2))
}

test.err

```

Validació creuada

```{r}

rf_model <- train(matriz_pred[train,], resposta[train],
                  method = "rf",
                  trControl = train_control,
                  metric = "Rsquared")
print(rf_model)

```

Calculam les mètriques de l'ajustament

```{r}

# Calculam R^2 de les dades test

r2_rf <- r_squared(radiomica_test_resposta, yhat)
r2_rf

mse_rf <- mse(radiomica_test_resposta,yhat)

mse_rf
```

Finalment, vegem quines han estat les variables més importants a l'hora de crear el noste model.

```{r}
importance(rf.radiomica_data)
```

```{r}
importance_df <- as.data.frame(importance(rf.radiomica_data))

# Afegir noms de columnes per claredat
colnames(importance_df) <- c("IncNodePurity")

# Ordenar les variables per importància decreixent
importance_df$Variable <- rownames(importance_df)
importance_df <- importance_df[order(importance_df$IncNodePurity, decreasing = TRUE), ]

# Gràfica de barres de la importància de les variables
ggplot(importance_df, aes(x = reorder(Variable, IncNodePurity), y = IncNodePurity), col = colorTFG) +
  geom_bar(stat = "identity", fill = colorTFG) +
  coord_flip() +
  xlab("") +
  ylab("Increment de la Puresa del Node (IncNodePurity)") +
  ggtitle("Importància de les Variables en el Random Forest") + 
  theme_minimal()
```

## GAM

En aquest apartat entrenarem el model GAM per a intentar trobar un relació no lineal entre els prdictors i la variable resposta.

```{r}
importance_df
```

```{r}
gam2 <- gam::gam(OS ~ gam::s(original_shape_SurfaceVolumeRatio) + gam::s(original_shape_SurfaceArea) +
                   gam::s(original_glcm_SumAverage) + gam::s(original_glszm_SmallAreaEmphasis) + 
                    gam::s(original_firstorder_MeanAbsoluteDeviation) + gam::s(original_glrlm_GrayLevelNonUniformity)
                 , data = radiomica_colin_train)
#summary(gam2)
plot(gam2, se = TRUE, col=colorTFG)
```

Durem a terme la validació creuada

```{r}
gam_model <- train(
  OS ~ original_shape_SurfaceVolumeRatio + original_shape_SurfaceArea +
                  original_glcm_SumAverage + original_glszm_SmallAreaEmphasis + 
                    original_firstorder_MeanAbsoluteDeviation + original_glrlm_GrayLevelNonUniformity,
  data = radiomica_colin_train,
  method = "gam",
  trControl = train_control)
gam_model
```

```{r}
summary(gam2)
```

```{r}
pred = predict(gam2, newdata = radiomica_colin_test)
pred
```

Calculam les mètriques d'ajustament

```{r}
r2_gam <- r_squared(radiomica_test_resposta, pred)
r2_gam

mse_gam <- mse(radiomica_test_resposta, pred)
mse_gam

```
